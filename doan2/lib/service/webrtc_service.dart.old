import 'dart:async';
import 'package:flutter/foundation.dart';
import 'package:flutter_webrtc/flutter_webrtc.dart';
import 'socket_service.dart';
import 'package:app_iot/core/utils/permission_helper.dart';

/// WebRTC Service - Quáº£n lÃ½ video call vá»›i peer-to-peer connection
/// Giá»‘ng Messenger: WebRTC + Socket.IO signaling
class WebRTCService {
  static final WebRTCService _instance = WebRTCService._internal();
  factory WebRTCService() => _instance;
  WebRTCService._internal();

  // --- STATE ---
  RTCPeerConnection? _peerConnection;
  MediaStream? _localStream;
  MediaStream? _remoteStream;
  
  String? _currentUserId;
  String? _currentUserName;
  String? _currentUserAvatar;
  
  String? _remoteUserId;
  String? _remoteUserName;
  String? _remoteUserAvatar;
  
  bool _isCallActive = false;
  bool _isCaller = false;
  bool _isMicOn = true;
  bool _isCameraOn = true;
  bool _isSpeakerOn = true;
  bool _isFrontCamera = true;
  String _callType = 'video'; // 'video' or 'audio'

  // --- SIGNALING SUBSCRIPTIONS ---
  StreamSubscription? _answerSubscription;
  StreamSubscription? _iceCandidateSubscription;
  
  // --- PENDING ICE CANDIDATES (received before peer connection ready) ---
  final List<Map<String, dynamic>> _pendingIceCandidates = [];
  
  // --- CALL TIMEOUT (Messenger-like: 60 seconds for no answer) ---
  Timer? _callTimeoutTimer;
  
  // --- CALL STATE TRACKING ---
  CallState _currentCallState = CallState.idle;

  // --- STREAMS ---
  final _localStreamController = StreamController<MediaStream?>.broadcast();
  final _remoteStreamController = StreamController<MediaStream?>.broadcast();
  final _callStateController = StreamController<CallState>.broadcast();
  
  Stream<MediaStream?> get localStream => _localStreamController.stream;
  Stream<MediaStream?> get remoteStream => _remoteStreamController.stream;
  Stream<CallState> get callState => _callStateController.stream;

  // --- GETTERS ---
  bool get isCallActive => _isCallActive;
  bool get isMicOn => _isMicOn;
  bool get isCameraOn => _isCameraOn;
  bool get isSpeakerOn => _isSpeakerOn;
  bool get isFrontCamera => _isFrontCamera;
  String get callType => _callType;
  MediaStream? get localStreamValue => _localStream;
  MediaStream? get remoteStreamValue => _remoteStream;
  String? get remoteUserName => _remoteUserName;
  String? get remoteUserAvatar => _remoteUserAvatar;
  
  // --- HELPER METHODS ---
  /// Update call state and notify listeners
  void _updateCallState(CallState newState) {
    _currentCallState = newState;
    _callStateController.add(newState);
  }

  // --- CONFIGURATION ---
  // ICE Servers cho táº¥t cáº£ platforms - ThÃªm backup STUN/TURN servers
  final Map<String, dynamic> _iceServers = {
    'iceServers': [
      {
        'urls': [
          'stun:stun.l.google.com:19302',
          'stun:stun1.l.google.com:19302',
          'stun:stun2.l.google.com:19302',
          'stun:stun3.l.google.com:19302',
          'stun:stun4.l.google.com:19302',
        ]
      },
      // ThÃªm STUN server backup
      {
        'urls': 'stun:stun.relay.metered.ca:80'
      },
      // Free public TURN servers for NAT traversal - Updated with multiple providers
      {
        'urls': 'turn:openrelay.metered.ca:80',
        'username': 'openrelayproject',
        'credential': 'openrelayproject',
      },
      {
        'urls': 'turn:openrelay.metered.ca:443',
        'username': 'openrelayproject',
        'credential': 'openrelayproject',
      },
      {
        'urls': 'turn:openrelay.metered.ca:443?transport=tcp',
        'username': 'openrelayproject',
        'credential': 'openrelayproject',
      },
      // Additional free TURN server
      {
        'urls': 'turn:relay1.expressturn.com:3478',
        'username': 'efF8VNZ8KYLR7G89QS',
        'credential': 'zuOl6CtwZJ0XqZsK',
      },
    ],
    // Force ICE to use relay candidates (TURN) as well
    'iceTransportPolicy': 'all',
    'iceCandidatePoolSize': 10,
    // ThÃªm config cho cross-platform
    'iceCandidatePoolSize': 10,
  };

  // Media constraints tÆ°Æ¡ng thÃ­ch vá»›i táº¥t cáº£ platforms (Android, iOS, Desktop, Web)
  Map<String, dynamic> _mediaConstraintsForType(String callType) {
    final bool videoEnabled = callType == 'video';
    
    // Unified 16:9 aspect ratio (1280x720) for all platforms
    // This ensures consistent video quality and prevents distortion
    if (kIsWeb) {
      // Web: DÃ¹ng standard WebRTC constraints
      return {
        'audio': true,
        'video': videoEnabled ? {
          'facingMode': 'user',
          'width': {'ideal': 1280},
          'height': {'ideal': 720},
          'aspectRatio': {'ideal': 16.0 / 9.0},
        } : false
      };
    } else if (defaultTargetPlatform == TargetPlatform.windows ||
               defaultTargetPlatform == TargetPlatform.macOS ||
               defaultTargetPlatform == TargetPlatform.linux) {
      // Desktop: 1280x720 (16:9)
      return {
        'audio': true,
        'video': videoEnabled ? {
          'width': 1280,
          'height': 720,
        } : false
      };
    } else {
      // Mobile (Android/iOS): Chuáº©n hÃ³a vá» 1280x720 (16:9) thay vÃ¬ 640x480 (4:3)
      return {
        'audio': true,
        'video': videoEnabled ? {
          'mandatory': {
            'minWidth': '1280',
            'minHeight': '720',
            'minFrameRate': '30',
          },
          'facingMode': 'user',
          'optional': [],
        } : false
      };
    }
  }

  // --- INITIALIZATION ---
  
  /// Initialize user info (gá»i sau khi login)
  void initUser({
    required String userId,
    required String userName,
    String? avatarUrl,
  }) {
    _currentUserId = userId;
    _currentUserName = userName;
    _currentUserAvatar = avatarUrl;
    print("âœ… [WebRTC] User initialized: $userId");
  }

  /// Setup signaling listeners (answer, ICE candidates)
  void _setupSignalingListeners() {
    print('ğŸ”” [WebRTC] Setting up signaling listeners...');
    
    // Cancel existing subscriptions
    _answerSubscription?.cancel();
    _iceCandidateSubscription?.cancel();
    
    final socketService = SocketService();
    
    // Listen for answer (when we are caller)
    _answerSubscription = socketService.webrtcAnswerStream.listen((data) async {
      if (!_isCaller || _peerConnection == null) return;
      
      final fromUserId = data['from']?.toString() ?? '';
      if (fromUserId != _remoteUserId) {
        print('âš ï¸ [WebRTC] Received answer from wrong user: $fromUserId');
        return;
      }
      
      final answer = data['answer'] as Map<String, dynamic>?;
      if (answer == null) {
        print('âŒ [WebRTC] Answer is null');
        return;
      }
      
      print('âœ… [WebRTC] Processing answer from $fromUserId...');
      await handleAnswer(answer);
    });
    
    // Listen for ICE candidates
    _iceCandidateSubscription = socketService.webrtcIceCandidateStream.listen((data) async {
      if (_peerConnection == null) {
        print('! [WebRTC] Cannot add ICE candidate - Peer connection is null');
        return;
      }
      
      final fromUserId = data['from']?.toString() ?? '';
      if (fromUserId != _remoteUserId) {
        print('âš ï¸ [WebRTC] Received ICE from wrong user: $fromUserId');
        return;
      }
      
      final candidate = data['candidate'] as Map<String, dynamic>?;
      if (candidate == null) {
        print('âŒ [WebRTC] ICE candidate is null');
        return;
      }
      
      await handleIceCandidate(candidate);
    });
    
    print('âœ… [WebRTC] Signaling listeners ready');
  }
  
  /// Cancel signaling listeners
  void _cancelSignalingListeners() {
    _answerSubscription?.cancel();
    _iceCandidateSubscription?.cancel();
    _answerSubscription = null;
    _iceCandidateSubscription = null;
  }

  // --- CALL INITIATION ---
  
  /// Báº¯t Ä‘áº§u cuá»™c gá»i (caller)
  Future<bool> startCall({
    required String remoteUserId,
    required String remoteUserName,
    String? remoteUserAvatar,
    String callType = 'video', // 'video' or 'audio'
  }) async {
    if (_isCallActive) {
      print("âš ï¸ [WebRTC] Äang trong cuá»™c gá»i khÃ¡c");
      return false;
    }

    try {
      print('\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
      print('ğŸ“ [WebRTC] STARTING OUTGOING CALL');
      print('   Caller: $_currentUserName ($_currentUserId)');
      print('   Callee: $remoteUserName ($remoteUserId)');
      print('   Call Type: $callType');
      print('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
      
      _remoteUserId = remoteUserId;
      _remoteUserName = remoteUserName;
      _remoteUserAvatar = remoteUserAvatar;
      _callType = callType;
      _isCaller = true;
      _isCallActive = true;
      
      _updateCallState(CallState.connecting);

      // 0. Setup signaling listeners FIRST
      print('ğŸ”” Step 0: Setting up signaling listeners...');
      _setupSignalingListeners();
      print('âœ… Step 0: Signaling listeners ready\n');

      // 1. Get local media
      print('ğŸ¬ Step 1: Getting local media...');
      await _getLocalMedia();
      print('âœ… Step 1: Local media obtained\n');
      
      // 2. Create peer connection
      print('ğŸ”— Step 2: Creating peer connection...');
      await _createPeerConnection();
      print('âœ… Step 2: Peer connection created\n');
      
      // 3. Create and send offer
      print('ğŸ“¤ Step 3: Creating offer...');
      RTCSessionDescription offer = await _peerConnection!.createOffer();
      await _peerConnection!.setLocalDescription(offer);
      print('âœ… Step 3: Offer created and set as local description');
      print('   Offer type: ${offer.type}');
      print('   SDP length: ${offer.sdp?.length ?? 0} chars\n');
      
      // 4. Send offer via Socket.IO
      print('ğŸ“¤ Step 4: Sending offer via Socket.IO...');
      SocketService().sendCallOffer(
        targetUserId: remoteUserId,
        offer: offer.toMap(),
        callerName: _currentUserName ?? 'User',
        callerAvatar: _currentUserAvatar,
        callType: callType,
      );

      _updateCallState(CallState.ringing);
      print('\nâœ… [WebRTC] Call initiated successfully!');
      print('   â³ Waiting for answer from $remoteUserName...');
      print('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
      
      // Messenger-like: Auto-cancel call if no answer after 60 seconds
      _callTimeoutTimer?.cancel();
      _callTimeoutTimer = Timer(const Duration(seconds: 60), () async {
        if (_currentCallState != CallState.connected) {
          print('â±ï¸ [WebRTC] Call timeout - no answer after 60 seconds');
          _updateCallState(CallState.timeout);
          
          // Notify remote peer about timeout BEFORE ending
          if (_remoteUserId != null) {
            SocketService().sendCallEnded(
              targetUserId: _remoteUserId!,
              reason: 'timeout',
            );
          }
          
          await endCall(sendNotification: false); // Don't send again
        }
      });
      
      return true;
    } catch (e) {
      print('\nâŒ [WebRTC] ERROR during startCall: $e');
      print('   Stack trace: ${StackTrace.current}');
      print('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
      await endCall();
      return false;
    }
  }

  /// Nháº­n cuá»™c gá»i (receiver)
  Future<bool> acceptCall({
    required Map<String, dynamic> offer,
    required String callerUserId,
    required String callerUserName,
    String? callerUserAvatar,
    String callType = 'video', // 'video' or 'audio'
  }) async {
    if (_isCallActive) {
      print("âš ï¸ [WebRTC] Äang trong cuá»™c gá»i khÃ¡c");
      return false;
    }

    try {
      print('\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
      print('ğŸ“ [WebRTC] ACCEPTING INCOMING CALL');
      print('   Receiver: $_currentUserName ($_currentUserId)');
      print('   Caller: $callerUserName ($callerUserId)');
      print('   Call Type: $callType');
      print('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
      
      _remoteUserId = callerUserId;
      _remoteUserName = callerUserName;
      _remoteUserAvatar = callerUserAvatar;
      _callType = callType;
      _isCaller = false;
      _isCallActive = true;
      
      _updateCallState(CallState.connecting);

      // 0. Setup signaling listeners FIRST (for ICE candidates)
      print('ğŸ”” Step 0: Setting up signaling listeners...');
      _setupSignalingListeners();
      print('âœ… Step 0: Signaling listeners ready\n');

      // 1. Get local media
      print('ğŸ¬ Step 1: Getting local media...');
      try {
        await _getLocalMedia();
        print('âœ… Step 1: Local media obtained\n');
      } catch (e) {
        print('âŒ Step 1 FAILED: Could not get local media');
        print('   Error: $e');
        print('   ğŸ’¡ This usually means:');
        print('      - Camera/mic permissions denied');
        print('      - Camera is in use by another app');
        print('      - No camera/mic hardware detected');
        throw Exception('Failed to get camera/microphone: $e');
      }
      
      // 2. Create peer connection
      print('ğŸ”— Step 2: Creating peer connection...');
      await _createPeerConnection();
      print('âœ… Step 2: Peer connection created\n');
      
      // 2.1. Replay any pending ICE candidates
      if (_pendingIceCandidates.isNotEmpty) {
        print('ğŸ“¦ Step 2.1: Replaying ${_pendingIceCandidates.length} pending ICE candidates...');
        for (var candidate in _pendingIceCandidates) {
          await handleIceCandidate(candidate);
        }
        _pendingIceCandidates.clear();
        print('âœ… Step 2.1: All pending ICE candidates processed\n');
      }
      
      // 3. Set remote description (offer)
      print('ğŸ“¥ Step 3: Setting remote description (offer)...');
      await _peerConnection!.setRemoteDescription(
        RTCSessionDescription(offer['sdp'], offer['type'])
      );
      print('âœ… Step 3: Remote description set');
      print('   Offer type: ${offer['type']}');
      print('   SDP length: ${offer['sdp']?.toString().length ?? 0} chars\n');
      
      // 4. Create and send answer
      print('ğŸ“¤ Step 4: Creating answer...');
      RTCSessionDescription answer = await _peerConnection!.createAnswer();
      await _peerConnection!.setLocalDescription(answer);
      print('âœ… Step 4: Answer created and set as local description');
      print('   Answer type: ${answer.type}');
      print('   SDP length: ${answer.sdp?.length ?? 0} chars\n');
      
      // 5. Send answer via Socket.IO
      print('ğŸ“¤ Step 5: Sending answer via Socket.IO...');
      SocketService().sendCallAnswer(
        targetUserId: callerUserId,
        answer: answer.toMap(),
      );

      // Keep state as connecting - will update to connected when onTrack fires
      // This prevents premature "connected" state before video arrives
      print('â³ Waiting for remote track to arrive...');
      print('\nâœ… [WebRTC] Call accepted successfully! Waiting for video stream...');
      print('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
      
      return true;
    } catch (e, stackTrace) {
      print('\nâŒ [WebRTC] ERROR during acceptCall: $e');
      print('   Stack trace: $stackTrace');
      print('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
      await endCall();
      return false;
    }
  }

  /// Xá»­ lÃ½ answer tá»« remote peer (cho caller)
  Future<void> handleAnswer(Map<String, dynamic> answer) async {
    try {
      if (_peerConnection == null) {
        print('âš ï¸ [WebRTC] Cannot handle answer - Peer connection is null');
        return;
      }

      // Check current signaling state
      final currentState = await _peerConnection!.getSignalingState();
      print('\nğŸ“© [WebRTC] â•â•â• HANDLING ANSWER â•â•â•');
      print('   Current signaling state: $currentState');
      print('   Answer type: ${answer['type']}');
      print('   SDP length: ${answer['sdp']?.toString().length ?? 0} chars');
      
      // Only set remote description if we're in the correct state
      if (currentState == RTCSignalingState.RTCSignalingStateHaveLocalOffer) {
        await _peerConnection!.setRemoteDescription(
          RTCSessionDescription(answer['sdp'], answer['type'])
        );
        
        // Cancel timeout timer - call was answered!
        _callTimeoutTimer?.cancel();
        
        _updateCallState(CallState.connected);
        print('   âœ… Remote description set');
        print('   âœ… Call connected!');
      } else if (currentState == RTCSignalingState.RTCSignalingStateStable) {
        print('   âš ï¸ Already in stable state - answer already processed');
      } else {
        print('   âš ï¸ Wrong signaling state for answer: $currentState');
      }
      print('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
    } catch (e) {
      print('\nâŒ [WebRTC] ERROR handling answer: $e');
      print('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
      // Don't end call immediately - might be duplicate answer
    }
  }

  /// Xá»­ lÃ½ ICE candidate tá»« remote peer
  Future<void> handleIceCandidate(Map<String, dynamic> candidate) async {
    try {
      if (_peerConnection == null) {
        // Queue the ICE candidate for later when peer connection is ready
        _pendingIceCandidates.add(candidate);
        print('ğŸ“¦ [WebRTC] Queued ICE candidate (peer connection not ready yet, pending: ${_pendingIceCandidates.length})');
        return;
      }
      
      final candidateStr = candidate['candidate']?.toString() ?? '';
      final candidateType = candidateStr.contains('typ relay') ? 'relay (TURN)' :
                           candidateStr.contains('typ srflx') ? 'srflx (STUN)' :
                           candidateStr.contains('typ host') ? 'host' : 'unknown';
      
      print('\nğŸ§Š [WebRTC] â•â•â• ADDING ICE CANDIDATE â•â•â•');
      print('   Candidate: ${candidateStr.substring(0, 50)}...');
      print('   Type: $candidateType');
      print('   sdpMid: ${candidate['sdpMid']}');
      print('   sdpMLineIndex: ${candidate['sdpMLineIndex']}');
      
      await _peerConnection!.addCandidate(
        RTCIceCandidate(
          candidate['candidate'],
          candidate['sdpMid'],
          candidate['sdpMLineIndex'],
        )
      );
      print('   âœ… ICE candidate added successfully');
      print('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
    } catch (e) {
      print('\nâŒ [WebRTC] ERROR adding ICE candidate: $e');
      print('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
    }
  }

  // --- INTERNAL METHODS ---
  
  Future<void> _getLocalMedia() async {
    try {
      print("ğŸ¥ [WebRTC] Requesting media permissions (callType: $_callType)...");
      
      // [FIX] Request permissions trÆ°á»›c khi gá»i getUserMedia
      bool permissionsGranted = await PermissionHelper.requestWebRTCPermissions();
      if (!permissionsGranted) {
        throw Exception('Camera/Microphone permissions denied');
      }
      print("âœ… [WebRTC] Permissions granted");
      
      // [FIX] Multi-tier fallback strategy
      print("ğŸ¥ [WebRTC] Getting user media with platform-specific constraints...");
      
      try {
        // Tier 1: Try platform-specific constraints
        _localStream = await navigator.mediaDevices.getUserMedia(_mediaConstraintsForType(_callType));
        print("âœ… [WebRTC] Got media with primary constraints ($_callType mode)");
        
      } catch (e1) {
        print("âš ï¸ [WebRTC] Primary constraints failed: $e1");
        
        if (_callType == 'video') {
          print("ğŸ”„ [WebRTC] Trying fallback constraints (640x480)...");
          
          try {
            // Tier 2: Lower resolution (good for Windows)
            final fallbackConstraints = {
              'audio': true,
              'video': {
                'width': 640,
                'height': 480,
                'frameRate': 15,
              }
            };
            _localStream = await navigator.mediaDevices.getUserMedia(fallbackConstraints);
            print("âœ… [WebRTC] Got media with fallback constraints (640x480)");
            
          } catch (e2) {
            print("âš ï¸ [WebRTC] Fallback 640x480 failed: $e2");
            print("ğŸ”„ [WebRTC] Trying minimal constraints...");
            
            try {
              // Tier 3: Minimal (let OS/browser choose)
              _localStream = await navigator.mediaDevices.getUserMedia({
                'audio': true,
                'video': true,
              });
              print("âœ… [WebRTC] Got media with minimal constraints");
              
            } catch (e3) {
              print("âŒ [WebRTC] All video constraints failed");
              throw Exception('Failed to access camera/microphone: ${e3.toString()}');
            }
          }
        } else {
          // Audio-only call - if primary fails, just try minimal audio
          try {
            _localStream = await navigator.mediaDevices.getUserMedia({
              'audio': true,
              'video': false,
            });
            print("âœ… [WebRTC] Got audio-only stream");
          } catch (e2) {
            print("âŒ [WebRTC] Failed to get audio stream: $e2");
            throw Exception('Failed to access microphone: ${e2.toString()}');
          }
        }
      }
      
      if (_localStream == null || _localStream!.getTracks().isEmpty) {
        throw Exception('Failed to get local stream');
      }
      
      _localStreamController.add(_localStream);
      print("âœ… [WebRTC] Local media ready - Tracks: ${_localStream!.getTracks().length}");
      
      // Log tracks info
      for (var track in _localStream!.getTracks()) {
        print("   Track: ${track.kind} - ${track.label} - Enabled: ${track.enabled}");
      }
    } catch (e) {
      print("âŒ [WebRTC] Failed to get local media: $e");
      rethrow;
    }
  }

  Future<void> _createPeerConnection() async {
    try {
      print('\nğŸ”§ [WebRTC] â•â•â• CREATING PEER CONNECTION â•â•â•');
      print('   ICE Servers: ${_iceServers['iceServers']?.length ?? 0} servers configured');
      
      _peerConnection = await createPeerConnection(_iceServers);
      print('   âœ… Peer connection created');
      
      // Add local tracks
      int trackCount = 0;
      _localStream?.getTracks().forEach((track) {
        _peerConnection?.addTrack(track, _localStream!);
        trackCount++;
        print('   ğŸ“ Added local track: ${track.kind} (${track.label})');
      });
      print('   âœ… Added $trackCount local tracks\n');

      // Listen for remote stream
      _peerConnection?.onTrack = (RTCTrackEvent event) {
        print('\nğŸ“¡ [WebRTC] â•â•â• REMOTE TRACK RECEIVED â•â•â•');
        print('   Track kind: ${event.track.kind}');
        print('   Track ID: ${event.track.id}');
        print('   Streams count: ${event.streams.length}');
        print('   Is caller: ${_isCaller}');
        
        if (event.streams.isNotEmpty) {
          // Get incoming stream
          final incomingStream = event.streams[0];
          final incomingTrackCount = incomingStream.getTracks().length;
          
          // If we don't have a remote stream yet, use the incoming one
          if (_remoteStream == null) {
            _remoteStream = incomingStream;
            print('   ğŸ“º Created new remote stream: ${_remoteStream!.id}');
            print('   ğŸ“Š Initial track count: $incomingTrackCount');
          } else {
            // If incoming stream has different ID or more tracks, update it
            final currentTrackCount = _remoteStream!.getTracks().length;
            if (incomingStream.id != _remoteStream!.id || incomingTrackCount > currentTrackCount) {
              print('   ğŸ”„ Updating remote stream (from ${currentTrackCount} to ${incomingTrackCount} tracks)');
              _remoteStream = incomingStream;
            } else {
              print('   â„¹ï¸ Keeping existing stream (already has ${currentTrackCount} tracks)');
            }
          }
          
          // IMMEDIATELY push to controller so UI updates
          _remoteStreamController.add(_remoteStream);
          print('   âœ… Remote stream pushed to controller');
          print('   ğŸ“º Stream ID: ${_remoteStream!.id}');
          print('   ğŸ“Š Total tracks: ${_remoteStream!.getTracks().length}');
          for (var track in _remoteStream!.getTracks()) {
            final trackId = track.id ?? 'unknown';
            final trackIdPreview = trackId.length > 20 ? trackId.substring(0, 20) : trackId;
            print('      - ${track.kind}: $trackIdPreview... (enabled: ${track.enabled})');
          }
          
          // Update call state to connected when we have both audio and video
          if (_currentCallState == CallState.connecting && 
              _remoteStream!.getTracks().length >= 2) {
            _updateCallState(CallState.connected);
            print('   âœ… Call state updated to CONNECTED (both tracks received)');
          }
        }
        print('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
      };

      // Listen for ICE candidates
      _peerConnection?.onIceCandidate = (RTCIceCandidate candidate) {
        if (candidate.candidate != null && _remoteUserId != null) {
          final candidateStr = candidate.candidate ?? '';
          final candidateType = candidateStr.contains('typ relay') ? 'relay (TURN)' :
                               candidateStr.contains('typ srflx') ? 'srflx (STUN)' :
                               candidateStr.contains('typ host') ? 'host' : 'unknown';
          
          print('\nğŸ§Š [WebRTC] â•â•â• LOCAL ICE CANDIDATE GENERATED â•â•â•');
          print('   Candidate: ${candidateStr.substring(0, 50)}...');
          print('   Type: $candidateType');
          print('   To User: $_remoteUserId');
          
          SocketService().sendIceCandidate(
            targetUserId: _remoteUserId!,
            candidate: candidate.toMap(),
          );
          print('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
        }
      };

      // Listen for ICE connection state changes
      _peerConnection?.onIceConnectionState = (RTCIceConnectionState state) {
        print('\nğŸ”„ [WebRTC] â•â•â• ICE CONNECTION STATE CHANGED â•â•â•');
        print('   New State: $state');
        
        switch (state) {
          case RTCIceConnectionState.RTCIceConnectionStateNew:
            print('   â„¹ï¸  ICE agent is gathering addresses');
            break;
          case RTCIceConnectionState.RTCIceConnectionStateChecking:
            print('   ğŸ” ICE agent is checking candidates');
            break;
          case RTCIceConnectionState.RTCIceConnectionStateConnected:
            print('   âœ… ICE agent has found a usable connection');
            // Restore to connected state if we were reconnecting
            if (_currentCallState == CallState.reconnecting) {
              print('   âœ… [WebRTC] Connection restored!');
              _updateCallState(CallState.connected);
            }
            break;
          case RTCIceConnectionState.RTCIceConnectionStateCompleted:
            print('   âœ… ICE agent has finished gathering candidates');
            break;
          case RTCIceConnectionState.RTCIceConnectionStateFailed:
            print('   âŒ ICE agent failed to find a connection');
            print('   ğŸ”„ Attempting ICE restart...');
            // Don't end call immediately - try ICE restart first
            if (_currentCallState == CallState.connected || _currentCallState == CallState.connecting) {
              _updateCallState(CallState.reconnecting);
              _peerConnection?.restartIce();
              // Give it 20 seconds to recover before ending
              Future.delayed(const Duration(seconds: 20), () {
                if (_currentCallState == CallState.reconnecting) {
                  print('   âŒ [WebRTC] ICE restart failed - ending call');
                  endCall();
                }
              });
            }
            break;
          case RTCIceConnectionState.RTCIceConnectionStateDisconnected:
            print('   âš ï¸  ICE agent is disconnected - attempting to reconnect...');
            // Messenger-like: Try to reconnect on disconnect
            if (_currentCallState == CallState.connected) {
              _updateCallState(CallState.reconnecting);
              // Attempt ICE restart
              _peerConnection?.restartIce();
              // Auto-end call if reconnection fails after 15 seconds
              Future.delayed(const Duration(seconds: 15), () {
                if (_currentCallState == CallState.reconnecting) {
                  print('   âŒ [WebRTC] Reconnection timeout - ending call');
                  endCall();
                }
              });
            }
            break;
          case RTCIceConnectionState.RTCIceConnectionStateClosed:
            print('   ğŸ”’ ICE agent is closed');
            break;
          default:
            print('   âš ï¸  Unknown state: $state');
        }
        print('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
      };

      // Listen for connection state changes
      _peerConnection?.onConnectionState = (RTCPeerConnectionState state) {
        print('\nğŸ”— [WebRTC] â•â•â• PEER CONNECTION STATE CHANGED â•â•â•');
        print('   New State: $state');
        
        switch (state) {
          case RTCPeerConnectionState.RTCPeerConnectionStateNew:
            print('   â„¹ï¸  Connection is new');
            break;
          case RTCPeerConnectionState.RTCPeerConnectionStateConnecting:
            print('   ğŸ”„ Connection is being established');
            break;
          case RTCPeerConnectionState.RTCPeerConnectionStateConnected:
            print('   âœ… Connection established');
            break;
          case RTCPeerConnectionState.RTCPeerConnectionStateFailed:
            print('   âŒ Connection failed');
            break;
          case RTCPeerConnectionState.RTCPeerConnectionStateDisconnected:
            print('   âš ï¸  Connection disconnected');
            break;
          case RTCPeerConnectionState.RTCPeerConnectionStateClosed:
            print('   ğŸ”’ Connection closed');
            break;
          default:
            print('   âš ï¸  Unknown state: $state');
        }
        print('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
      };

      print('âœ… [WebRTC] Peer connection setup complete');
      print('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

      // Note: Connection state changes are monitored via ICE connection state handler
      // We don't immediately end call on state changes to allow for reconnection
      _peerConnection?.onConnectionState = (RTCPeerConnectionState state) {
        print("ğŸ”„ [WebRTC] Connection state: $state");
        // Don't end call here - let ICE restart mechanism handle failures
      };

      print("âœ… [WebRTC] Peer connection created");
    } catch (e) {
      print("âŒ [WebRTC] Lá»—i createPeerConnection: $e");
      rethrow;
    }
  }

  // --- CALL CONTROL ---
  
  /// Káº¿t thÃºc cuá»™c gá»i
  Future<void> endCall({bool sendNotification = true, String reason = 'ended'}) async {
    if (!_isCallActive) return;

    print("ğŸ“´ [WebRTC] Káº¿t thÃºc cuá»™c gá»i - Reason: $reason");
    
    // Cancel timeout timer
    _callTimeoutTimer?.cancel();

    // Cancel signaling listeners
    _cancelSignalingListeners();

    // Send notification to remote peer with reason
    if (sendNotification && _remoteUserId != null) {
      SocketService().sendCallEnded(
        targetUserId: _remoteUserId!,
        reason: reason,
      );
    }

    // Close peer connection with null check
    try {
      if (_peerConnection != null) {
        await _peerConnection!.close();
        _peerConnection = null;
      }
    } catch (e) {
      print('   âš ï¸ Error closing peer connection: $e');
      _peerConnection = null;
    }

    // Stop local tracks
    try {
      _localStream?.getTracks().forEach((track) => track.stop());
      _localStream?.dispose();
      _localStream = null;
    } catch (e) {
      print('   âš ï¸ Error disposing local stream: $e');
      _localStream = null;
    }

    // Clear remote stream
    try {
      _remoteStream?.dispose();
      _remoteStream = null;
    } catch (e) {
      print('   âš ï¸ Error disposing remote stream: $e');
      _remoteStream = null;
    }

    _localStreamController.add(null);
    _remoteStreamController.add(null);
    _updateCallState(CallState.ended);

    _isCallActive = false;
    _remoteUserId = null;
    _remoteUserName = null;
    _remoteUserAvatar = null;
    
    print("âœ… [WebRTC] ÄÃ£ dá»n dáº¹p");
  }

  /// Tá»« chá»‘i cuá»™c gá»i
  Future<void> rejectCall(String callerUserId) async {
    print('\nâŒ [WebRTC] â•â•â• REJECTING CALL â•â•â•');
    print('   Rejecting call from: $callerUserId');
    
    // Send rejection with proper reason
    SocketService().sendCallEnded(
      targetUserId: callerUserId,
      reason: 'rejected',
    );
    
    print('   âœ… Rejection sent');
    print('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
    
    await endCall(sendNotification: false);
  }

  // --- MEDIA CONTROL ---
  
  /// Toggle microphone
  Future<void> toggleMic() async {
    if (_localStream == null) return;
    
    _isMicOn = !_isMicOn;
    _localStream!.getAudioTracks().forEach((track) {
      track.enabled = _isMicOn;
    });
    print("ğŸ¤ [WebRTC] Mic: ${_isMicOn ? 'ON' : 'OFF'}");
  }

  /// Toggle camera
  Future<void> toggleCamera() async {
    if (_localStream == null) return;
    
    _isCameraOn = !_isCameraOn;
    _localStream!.getVideoTracks().forEach((track) {
      track.enabled = _isCameraOn;
    });
    print("ğŸ“¹ [WebRTC] Camera: ${_isCameraOn ? 'ON' : 'OFF'}");
  }

  /// Switch camera (front/back)
  Future<void> switchCamera() async {
    if (_localStream == null) return;
    
    final videoTrack = _localStream!.getVideoTracks().first;
    await Helper.switchCamera(videoTrack);
    _isFrontCamera = !_isFrontCamera;
    print("ğŸ”„ [WebRTC] Camera switched");
  }

  /// Toggle speaker
  Future<void> toggleSpeaker() async {
    _isSpeakerOn = !_isSpeakerOn;
    // Platform-specific implementation
    print("ğŸ”Š [WebRTC] Speaker: ${_isSpeakerOn ? 'ON' : 'OFF'}");
  }

  // --- CLEANUP ---
  
  void dispose() {
    endCall(sendNotification: false);
    _localStreamController.close();
    _remoteStreamController.close();
    _callStateController.close();
  }
}

/// Call states
enum CallState {
  idle,        // KhÃ´ng cÃ³ cuá»™c gá»i
  connecting,  // Äang káº¿t ná»‘i
  ringing,     // Äang Ä‘á»• chuÃ´ng
  connected,   // ÄÃ£ káº¿t ná»‘i
  reconnecting,// Äang káº¿t ná»‘i láº¡i (network issue)
  timeout,     // Háº¿t thá»i gian chá» (no answer)
  busy,        // NgÆ°á»i nháº­n Ä‘ang báº­n
  ended,       // Káº¿t thÃºc
}
